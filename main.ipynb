{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkking for ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"gemma2:2b\")\n",
    "\n",
    "response = llm.invoke(\"Why won't i find someone?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's tough to feel like you're not finding love or connection.  While I can't give you specific answers about your dating life, there are many possible reasons why this might be happening, and some things to consider: \n",
      "\n",
      "**Understanding Yourself & Your Goals:**\n",
      "\n",
      "* **Clear Vision:**  Do you have a clear idea of what kind of partner you want and what you're looking for in a relationship? Defining these qualities will help you focus your efforts.\n",
      "* **Self-Discovery:** Are you happy and fulfilled with yourself right now? If not, focusing on personal growth can improve your confidence and attractiveness to others. \n",
      "* **Emotional Maturity:**  Are you emotionally available for something deeper? Can you handle challenges and be open to vulnerability?\n",
      "\n",
      "**About Your Approach:**\n",
      "\n",
      "* **Networking & Exploration:**  Have you been putting yourself out there in ways that are comfortable and engaging? Joining social groups, attending events, and trying new hobbies can increase your chances of meeting someone.\n",
      "* **Online Dating Habits:** Are you using dating apps or websites effectively? Do you have a compelling profile and engaging photos? \n",
      "* **Communication Skills:**  Are you able to initiate conversations and express yourself clearly? Being confident and genuine in your interactions will attract people. \n",
      "\n",
      "**External Factors:**\n",
      "\n",
      "* **Location & Social Circle:** The area you live in, your social connections, and what activities you enjoy all play a role in who you meet.\n",
      "* **Life Circumstances:** Work, family commitments, or other life challenges can make it harder to focus on relationships. \n",
      "* **Time Management:**  Finding time for dating requires effort. Are you making intentional steps towards finding connection?\n",
      "\n",
      "**Remember:**\n",
      "\n",
      "* **Rejection is part of the process:** It's normal to experience some rejection when looking for love. Don't take it personally and use these experiences as learning opportunities. \n",
      "* **Be patient and kind to yourself:**  Don't rush the process. Finding love takes time, effort, and often a little bit of luck. \n",
      "* **Focus on building connections with people you enjoy.** Building healthy friendships can lead to deeper relationships over time.\n",
      "\n",
      "**If this is something that keeps weighing heavily on your mind, I recommend talking to someone you trust:** a therapist, friend, or family member. They can offer support and advice based on your unique situation. \n",
      "\n",
      "\n",
      "I hope this provides some helpful insights! Remember, finding love takes time, effort, and patience. Keep your chin up, stay positive, and keep exploring your options.  ‚ù§Ô∏è \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking for whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\github\\Assistant\\.venv\\Lib\\site-packages\\whisper\\__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "Oh! Oh hello!\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"oh_hello_deadpool.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from ollama)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting anyio (from httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in d:\\github\\assistant\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in d:\\github\\assistant\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Collecting sniffio (from httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading ollama-0.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, h11, httpcore, anyio, httpx, ollama\n",
      "Successfully installed anyio-4.4.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 ollama-0.3.1 sniffio-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install whisper ollama google-auth-oauthlib google-auth-httplib2 google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic working test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "Transcribed text: Oh! Oh hello!\n",
      "Ollama response: The user's input \"Oh! Oh hello!\" is an enthusiastic greeting.  \n",
      "\n",
      "**Action:** I should respond with a friendly greeting back. \n",
      "\n",
      "Here are some options:\n",
      "\n",
      "* **Option 1 (Casual):**  \"Hey there!\" \n",
      "* **Option 2 (More formal):** \"Hello! How can I help you today?\"\n",
      "* **Option 3 (Humorous):** \"Well, hello! Did a squirrel get into your voicebox?\"\n",
      "\n",
      "\n",
      "Which response would you prefer? üòä \n",
      "\n",
      "Text-to-speech output: The user's input \"Oh! Oh hello!\" is an enthusiastic greeting.  \n",
      "\n",
      "**Action:** I should respond with a friendly greeting back. \n",
      "\n",
      "Here are some options:\n",
      "\n",
      "* **Option 1 (Casual):**  \"Hey there!\" \n",
      "* **Option 2 (More formal):** \"Hello! How can I help you today?\"\n",
      "* **Option 3 (Humorous):** \"Well, hello! Did a squirrel get into your voicebox?\"\n",
      "\n",
      "\n",
      "Which response would you prefer? üòä \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import ollama\n",
    "import json\n",
    "import os\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    \n",
    "    # load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(audio_file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    # detect the spoken language\n",
    "    _, probs = model.detect_language(mel)\n",
    "    detected_language = max(probs, key=probs.get)\n",
    "    print(f\"Detected language: {detected_language}\")\n",
    "    \n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions()\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    \n",
    "    return result.text, detected_language\n",
    "\n",
    "def process_with_ollama(text, language):\n",
    "    # You can customize this prompt based on your needs\n",
    "    prompt = f\"\"\"\n",
    "    Language: {language}\n",
    "    User input: {text}\n",
    "    \n",
    "    Analyze the user's input and determine the appropriate action or response. \n",
    "    If it's a command or question, provide a suitable answer or action plan.\n",
    "    If it's a general statement, engage in a contextually appropriate conversation.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(model='gemma2:2b', messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful voice assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "def text_to_speech(text):\n",
    "    # Placeholder for text-to-speech functionality\n",
    "    # You can integrate a TTS library or service here\n",
    "    print(\"Text-to-speech output:\", text)\n",
    "\n",
    "def main():\n",
    "    audio_file = \"oh_hello_deadpool.mp3\"\n",
    "    \n",
    "    # Step 1: Transcribe audio\n",
    "    transcribed_text, detected_language = transcribe_audio(audio_file)\n",
    "    print(\"Transcribed text:\", transcribed_text)\n",
    "    \n",
    "    # Step 2: Process with Ollama\n",
    "    ollama_response = process_with_ollama(transcribed_text, detected_language)\n",
    "    print(\"Ollama response:\", ollama_response)\n",
    "    \n",
    "    # Step 3: Convert response to speech\n",
    "    text_to_speech(ollama_response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whisper\n",
      "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: ollama in d:\\github\\assistant\\.venv\\lib\\site-packages (0.3.1)\n",
      "Collecting google-auth-oauthlib\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-auth-httplib2\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.139.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six in d:\\github\\assistant\\.venv\\lib\\site-packages (from whisper) (1.16.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in d:\\github\\assistant\\.venv\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Collecting google-auth>=2.15.0 (from google-auth-oauthlib)\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting httplib2>=0.19.0 (from google-auth-httplib2)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Using cached protobuf-5.27.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in d:\\github\\assistant\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-auth-oauthlib)\n",
      "  Using cached cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-auth-oauthlib)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-auth-oauthlib)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2>=0.19.0->google-auth-httplib2)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: anyio in d:\\github\\assistant\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in d:\\github\\assistant\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\github\\assistant\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in d:\\github\\assistant\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\github\\assistant\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\github\\assistant\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\github\\assistant\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\assistant\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_api_python_client-2.139.0-py2.py3-none-any.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.1 MB 12.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.7/12.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.3/12.1 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "Downloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Using cached cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-5.27.3-cp310-abi3-win_amd64.whl (426 kB)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Building wheels for collected packages: whisper\n",
      "  Building wheel for whisper (pyproject.toml): started\n",
      "  Building wheel for whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41394 sha256=99e4716e668dd746015e12c6471be3f246c2541e7d6982b4f75febf3887701bb\n",
      "  Stored in directory: d:\\wpsystem\\s-1-5-21-4246136125-446009848-2652859690-1001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\21\\65\\ee\\4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
      "Successfully built whisper\n",
      "Installing collected packages: whisper, uritemplate, pyparsing, pyasn1, protobuf, oauthlib, cachetools, rsa, requests-oauthlib, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, google-auth, google-auth-oauthlib, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.4.0 google-api-core-2.19.1 google-api-python-client-2.139.0 google-auth-2.32.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.2.1 googleapis-common-protos-1.63.2 httplib2-0.22.0 oauthlib-3.2.2 proto-plus-1.24.0 protobuf-5.27.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 pyparsing-3.1.2 requests-oauthlib-2.0.0 rsa-4.9 uritemplate-4.1.1 whisper-1.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install whisper ollama google-auth-oauthlib google-auth-httplib2 google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytz\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Installing collected packages: pytz\n",
      "Successfully installed pytz-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed text: Hi, I will meet Rahul today around 8. So yeah, thanks.\n",
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Raw response from LLM: ```json\n",
      "{\"event\": {\"title\": \"Meeting with Rahul\", \"start_date_time\": \"2023-10-27T08:00:00\", \"end_date_time\": \"2023-10-27T09:00:00\", \"location\": null, \"description\": \"Meeting with Rahul at around 8\"}}\n",
      "``` \n",
      "\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **Event title:**  \"Meeting with Rahul\" is extracted from the user input.\n",
      "* **Start date and time:**  \"2023-10-27T08:00:00\" assumes this refers to the exact meeting start time, based on \"today\". \n",
      "* **End date and time:** \"2023-10-27T09:00:00\"  assumes a one-hour duration after the start. \n",
      "* **Location:** No specific location is mentioned in the user input, so we set the \"location\" field to null for now. You can update this if you receive more details from the user about where the meeting will take place. \n",
      "* **Description:**  The sentence \"So yeah, thanks\" provides no additional information about the meeting beyond the time and who is involved. \n",
      "\n",
      "\n",
      "Let me know if you need to extract more information based on the user's input!  \n",
      "Assistant: I'm sorry, but I encountered an error while processing your request. Could you please try rephrasing your input?\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import ollama\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/calendar']\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    if not os.path.exists(audio_file):\n",
    "        raise FileNotFoundError(f\"The audio file '{audio_file}' does not exist.\")\n",
    "    \n",
    "    try:\n",
    "        model = whisper.load_model(\"base\")\n",
    "        audio = whisper.load_audio(audio_file)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "        options = whisper.DecodingOptions()\n",
    "        result = whisper.decode(model, mel, options)\n",
    "        return result.text\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to transcribe audio: {str(e)}\")\n",
    "\n",
    "\n",
    "def natural_language_understanding(text):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following user input and extract information for creating a calendar event:\n",
    "    User input: {text}\n",
    "\n",
    "    Please provide the following details in JSON format:\n",
    "    1. Event title\n",
    "    2. Start date and time\n",
    "    3. End date and time (if specified, otherwise assume 1 hour duration)\n",
    "    4. Location (if specified)\n",
    "    5. Description (if any additional details are provided)\n",
    "\n",
    "    If the input doesn't contain enough information for a calendar event, respond with {{\"error\": \"Not enough information\"}}.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(model='gemma2:2b', messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant that extracts calendar event information from user input.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "def create_calendar_event(event_details):\n",
    "    print(\"started creating calendar event\")\n",
    "    creds = None\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('client_secret.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    \n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "    \n",
    "    event = {\n",
    "        'summary': event_details['title'],\n",
    "        'location': event_details.get('location', ''),\n",
    "        'description': event_details.get('description', ''),\n",
    "        'start': {\n",
    "            'dateTime': event_details['start'],\n",
    "            'timeZone': 'Europe/Oslos',\n",
    "        },\n",
    "        'end': {\n",
    "            'dateTime': event_details['end'],\n",
    "            'timeZone': 'Europe/Oslos',\n",
    "        },\n",
    "    }\n",
    "    print(\"almost created calendar event\")\n",
    "\n",
    "    event = service.events().insert(calendarId='primary', body=event).execute()\n",
    "    return f\"Event created: {event.get('htmlLink')}\"\n",
    "\n",
    "def text_to_speech(text):\n",
    "    # Placeholder for text-to-speech functionality\n",
    "    print(\"Assistant:\", text)\n",
    "\n",
    "def main():\n",
    "    audio_file = \"recordings\\meet_at_8.mp3\"\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Speech-to-Text\n",
    "        transcribed_text = transcribe_audio(audio_file)\n",
    "        print(\"Transcribed text:\", transcribed_text)\n",
    "        \n",
    "        # Step 2: Natural Language Understanding\n",
    "        event_info_str = natural_language_understanding(transcribed_text)\n",
    "        \n",
    "        # Step 3: Intent Classification and Action\n",
    "        try:\n",
    "            event_info = json.loads(event_info_str)\n",
    "            if \"error\" in event_info:\n",
    "                response = \"I'm sorry, but I couldn't extract enough information to create a calendar event. Could you please provide more details?\"\n",
    "            else:\n",
    "                result = create_calendar_event(event_info)\n",
    "                response = f\"I've created the event for you. {result}\"\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {str(e)}\")\n",
    "            print(f\"Raw response from LLM: {event_info_str}\")\n",
    "            response = \"I'm sorry, but I encountered an error while processing your request. Could you please try rephrasing your input?\"\n",
    "        \n",
    "        # Step 4: Text-to-Speech\n",
    "        text_to_speech(response)\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"Please make sure the audio file exists and the path is correct.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"There was an issue processing the audio. Please try again or use a different audio file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "        print(\"Please try again or contact support if the issue persists.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2179933577.py, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 40\u001b[1;36m\u001b[0m\n\u001b[1;33m    def main():\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import ollama\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "def create_calendar_event(event_details):\n",
    "    print(\"started creating calendar event\")\n",
    "    creds = None\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('client_secret.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    \n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "    \n",
    "    event = {\n",
    "        'summary': event_details['title'],\n",
    "        'location': event_details.get('location', ''),\n",
    "        'description': event_details.get('description', ''),\n",
    "        'start': {\n",
    "            'dateTime': event_details['start'],\n",
    "            'timeZone': 'Europe/Oslos',\n",
    "        },\n",
    "        'end': {\n",
    "            'dateTime': event_details['end'],\n",
    "            'timeZone': 'Europe/Oslos',\n",
    "        },\n",
    "    }\n",
    "    print(\"almost created calendar event\")\n",
    "\n",
    "    event = service.events().insert(calendarId='primary', body=event).execute()\n",
    "    return f\"Event created: {event.get('htmlLink')}\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    json = {\"event\": {\"title\": \"Meeting with Rahul\", \"start_date_time\": \"2023-10-27T08:00:00\", \"end_date_time\": \"2023-10-27T09:00:00\", \"location\": null, \"description\": \"Meeting with Rahul at around 8\"}}\n",
    "    event_info = json.loads(json)\n",
    "    result = create_calendar_event(event_info)\n",
    "    response = f\"I've created the event for you. {result}\"\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
